
import cv2
import cvzone
import math
import streamlit as st
import numpy as np
from PIL import ImageFont, ImageDraw, Image
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av

# --- H√†m h·ªó tr·ª£ hi·ªÉn th·ªã ti·∫øng Vi·ªát ---
def draw_vietnamese_text(img1, text, position, font_size=24, color=(255, 255, 255)):
    img_pil = Image.fromarray(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        font = ImageFont.load_default()
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# --- Streamlit UI ---
st.set_page_config(page_title="AR Language Lens", page_icon="üì∏", layout="centered")
st.title("üì∑ AR Language Lens - YOLOv8")
st.write("Nh·∫≠n di·ªán v·∫≠t th·ªÉ v√† hi·ªÉn th·ªã t√™n ti·∫øng Vi·ªát üåè")

# --- Load model YOLO ---
import os
model_path = "yolov8m.pt"

# N·∫øu file ch∆∞a t·ªìn t·∫°i, t·∫£i l·∫°i model t·ª´ Ultralytics
if not os.path.exists(model_path):
    from ultralytics import YOLO
    model = YOLO('yolov8m.pt')  # t·ª± t·∫£i v·ªÅ t·ª´ hub
else:
    model = YOLO(model_path)

# Danh s√°ch l·ªõp ti·∫øng Vi·ªát
classNames = [
    "Person - Con ng∆∞·ªùi", "Bicycle - Xe ƒë·∫°p", "Car - √î t√¥", "Motorbike - Xe m√°y", "Aeroplane - M√°y bay",
    "Bus - Xe bu√Ωt", "Train - T√†u h·ªèa", "Truck - Xe t·∫£i", "Boat - Thuy·ªÅn",
    "Traffic Light - ƒê√®n giao th√¥ng", "Fire Hydrant - Tr·ª• n∆∞·ªõc c·ª©u h·ªèa", "Stop Sign - Bi·ªÉn d·ª´ng",
    "Parking Meter - ƒê·ªìng h·ªì ƒë·ªó xe", "Bench - Gh·∫ø d√†i", "Bird - Chim", "Cat - M√®o",
    "Dog - Ch√≥", "Horse - Ng·ª±a", "Sheep - C·ª´u", "Cow - B√≤", "Elephant - Voi", "Bear - G·∫•u",
    "Zebra - Ng·ª±a v·∫±n", "Giraffe - H∆∞∆°u cao c·ªï", "Backpack - Ba l√¥", "Umbrella - √î/D√π",
    "Handbag - T√∫i x√°ch", "Tie - C√† v·∫°t", "Suitcase - Vali", "Frisbee - ƒêƒ©a n√©m",
    "Skis - V√°n tr∆∞·ª£t tuy·∫øt", "Snowboard - V√°n tr∆∞·ª£t tuy·∫øt (M·ªôt t·∫•m)", "Sports Ball - B√≥ng th·ªÉ thao",
    "Kite - Di·ªÅu", "Baseball Bat - G·∫≠y b√≥ng ch√†y", "Baseball Glove - GƒÉng b√≥ng ch√†y",
    "Skateboard - V√°n tr∆∞·ª£t", "Surfboard - V√°n l∆∞·ªõt s√≥ng", "Tennis Racket - V·ª£t Tennis",
    "Bottle - Chai", "Wine Glass - Ly r∆∞·ª£u", "Cup - C·ªëc", "Fork - Nƒ©a", "Knife - Dao",
    "Spoon - Th√¨a", "Bowl - B√°t", "Banana - Chu·ªëi", "Apple - T√°o", "Sandwich - B√°nh Sandwich",
    "Orange - Cam", "Broccoli - B√¥ng c·∫£i xanh", "Carrot - C√† r·ªët", "Hot Dog - X√∫c x√≠ch k·∫πp b√°nh m√¨",
    "Pizza - B√°nh Pizza", "Donut - B√°nh Donut", "Cake - B√°nh kem", "Chair - Gh·∫ø",
    "Sofa - Gh·∫ø S√¥ Pha", "Potted Plant - C√¢y c·∫£nh", "Bed - Gi∆∞·ªùng", "Dining Table - B√†n ƒÉn",
    "Toilet - B·ªìn c·∫ßu", "TV Monitor - Tivi/M√†n h√¨nh", "Laptop - M√°y t√≠nh x√°ch tay",
    "Mouse - Chu·ªôt m√°y t√≠nh", "Remote - ƒêi·ªÅu khi·ªÉn", "Keyboard - B√†n ph√≠m", "Cell Phone - ƒêi·ªán tho·∫°i di ƒë·ªông",
    "Microwave - L√≤ vi s√≥ng", "Oven - L√≤ n∆∞·ªõng", "Toaster - M√°y n∆∞·ªõng b√°nh m√¨", "Sink - B·ªìn r·ª≠a",
    "Refrigerator - T·ªß l·∫°nh", "Book - S√°ch", "Clock - ƒê·ªìng h·ªì", "Vase - B√¨nh hoa",
    "Scissors - K√©o", "Teddy Bear - G·∫•u b√¥ng", "Hair Drier - M√°y s·∫•y t√≥c", "Toothbrush - B√†n ch·∫£i ƒë√°nh rƒÉng"
]

# --- Ch·ªçn ch·∫ø ƒë·ªô ---
mode = st.radio("Ch·ªçn ch·∫ø ƒë·ªô:", ["üñº Nh·∫≠n di·ªán ·∫£nh", "üìπ Nh·∫≠n di·ªán b·∫±ng webcam"])

# --- X·ª≠ l√Ω ·∫£nh upload ---
if mode == "üñº Nh·∫≠n di·ªán ·∫£nh":
    run = st.checkbox("B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán")
    uploaded_file = st.file_uploader("üìÅ T·∫£i ·∫£nh l√™n ƒë·ªÉ nh·∫≠n di·ªán", type=["jpg", "jpeg", "png"])
    FRAME_WINDOW = st.empty()

    if uploaded_file is not None and run:
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)

        results = model(img, stream=True)
        for r in results:
            boxes = r.boxes
            for box in boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                w, h = x2 - x1, y2 - y1
                cvzone.cornerRect(img, (x1, y1, w, h))
                conf = math.ceil((box.conf[0] * 100)) / 100
                if conf < 0.5:
                    continue
                cls = int(box.cls[0])
                label = f"{classNames[cls]} {conf:.2f}"
                img = draw_vietnamese_text(img, label, (x1, y1 - 25), font_size=24, color=(255, 0, 255))

        FRAME_WINDOW.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), channels="RGB")

    elif not run:
        st.info("üëÜ H√£y ch·ªçn ·∫£nh v√† b·∫≠t 'B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán' ƒë·ªÉ ch·∫°y m√¥ h√¨nh.")

# --- X·ª≠ l√Ω webcam ---
elif mode == "üìπ Nh·∫≠n di·ªán b·∫±ng webcam":

    class VideoTransformer(VideoTransformerBase):
        def __init__(self):
            self.model = model

        def transform(self, frame):
            img = frame.to_ndarray(format="bgr24")
            results = self.model(img, stream=True)
            for r in results:
                for box in r.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    w, h = x2 - x1, y2 - y1
                    cvzone.cornerRect(img, (x1, y1, w, h))
                    conf = math.ceil((box.conf[0] * 100)) / 100
                    if conf < 0.5:
                        continue
                    cls = int(box.cls[0])
                    label = f"{classNames[cls]} {conf:.2f}"
                    img = draw_vietnamese_text(img, label, (x1, y1 - 25), font_size=22, color=(255, 0, 255))
            return av.VideoFrame.from_ndarray(img, format="bgr24")

    webrtc_streamer(
        key="example",
        video_transformer_factory=VideoTransformer,
        media_stream_constraints={"video": True, "audio": False},
    )
    st.info("üì∏ Cho ph√©p quy·ªÅn truy c·∫≠p webcam khi tr√¨nh duy·ªát h·ªèi ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán.")



